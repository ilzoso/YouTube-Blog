{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8cc090",
   "metadata": {},
   "source": [
    "This notebook loads all the Question and Answer pairs from a CSV file\n",
    "Using a given input question, I would then:\n",
    "- Use query decomposition to construct multiple candidate subqueries\n",
    "- Feed the subqueries and the QnA pairs to a Cross-Encoder and return the top matching questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e467369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, SentencesDataset, SentenceTransformerTrainer, SentenceTransformerTrainingArguments, losses, SimilarityFunction\n",
    "from sentence_transformers.sampler import BatchSampler\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.losses import TripletLoss\n",
    "from sentence_transformers.readers import LabelSentenceReader, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset, Value\n",
    "import chromadb\n",
    "\n",
    "trained_model_path = \"models/all-MiniLM-L6-v2-trained\"\n",
    "model_r_name = \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n",
    "\n",
    "# Load fine-tuned model - we are using a Sentence-BERT model\n",
    "model2 = SentenceTransformer.load(trained_model_path)\n",
    "# Load Re-ranker model (cross encoder specifically)\n",
    "model_r = CrossEncoder(model_r_name)\n",
    "\n",
    "dataset = Dataset.from_csv(\"trading-v0.csv\")\n",
    "\n",
    "dataset = dataset.rename_column(\"Questions\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"Answers\", \"positive\")\n",
    "dataset = dataset.map(lambda e, i: {'negative': f\"I do not know\"}, with_indices=True).cast_column('negative', Value(dtype='string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09552a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='', cache=False, temperature=0)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f257ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy import Signature\n",
    "decomposer = dspy.Predict('question, context -> subquestions: list, confidence: float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"..................\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5539ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = decomposer(question=f\"Decompose this complex question into relevant sub-questions. \\n\\n{question}\")\n",
    "\n",
    "subquestions = []\n",
    "for subq in res.subquestions:\n",
    "    if type(subq) is dict:\n",
    "        subquestions.append(subq['question'])\n",
    "    else:\n",
    "        subquestions.append(subq)\n",
    "print(subquestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "queries = subquestions\n",
    "sentences = dataset['anchor']\n",
    "candidates = sentences\n",
    "\n",
    "all_pairs = [(q, c) for q in queries for c in candidates]\n",
    "all_scores = model_r.predict(all_pairs)\n",
    "\n",
    "print(sorted(all_scores, reverse=True))\n",
    "\n",
    "best_idx = np.argmax(all_scores)\n",
    "best_pair = all_pairs[best_idx]\n",
    "response = next((x['positive'] for x in dataset if x['anchor'] == best_pair[1]), None)\n",
    "print(f\"Best Global Match:\\n  Query: {best_pair[0]}\\n  Candidate: {best_pair[1]}\\n  Response: {response}\\n  Score: {all_scores[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aaf5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = model_r.rank(question, sentences)\n",
    "print(f\"Query ==> {question}\")\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t {sentences[rank['corpus_id']]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
