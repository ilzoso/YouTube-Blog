{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, SentencesDataset, SentenceTransformerTrainer, SentenceTransformerTrainingArguments, losses, SimilarityFunction\n",
    "from sentence_transformers.sampler import BatchSampler\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.losses import TripletLoss\n",
    "from sentence_transformers.readers import LabelSentenceReader, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset, Value\n",
    "import chromadb\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "trained_model_path = \"models/all-MiniLM-L6-v2-trained\"\n",
    "\n",
    "# Load pre-trained model - we are using a Sentence-BERT model\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "dataset = Dataset.from_csv(\"trading-v0.csv\")\n",
    "#dataset = load_dataset(\"json\", data_files=\"registration-v1.jsonl\")\n",
    "print(f\"DataSet shape (original) = {dataset.shape}\")\n",
    "\n",
    "dataset = dataset.rename_column(\"Questions\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"Answers\", \"positive\")\n",
    "dataset = dataset.rename_column(\"Link to Guide/Policy\", \"reference\")\n",
    "dataset = dataset.map(lambda e, i: {'negative': f\"I do not know\"}, with_indices=True).cast_column('negative', Value(dtype='string'))\n",
    "dataset = dataset.map(lambda e, i: {'qna': f\"{e['anchor']} {e['positive']}\"}, with_indices=True).cast_column('qna', Value(dtype='string'))\n",
    "print(f\"DataSet shape (after renaming) = {dataset.shape}\")\n",
    "\n",
    "train_dataset = dataset.select_columns([\"anchor\", \"positive\", \"negative\"]).take(30)\n",
    "eval_dataset = dataset.select_columns([\"anchor\", \"positive\", \"negative\"]).skip(30).take(10)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    print(f\"{i+1}\\t: {dataset[i]['anchor']} \\t==>\\t {dataset[i]['positive']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb892900",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    #output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
    "    output_dir=trained_model_path,\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # losses that use \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    run_name=\"mpnet-base-all-nli-triplet\",  # Will be used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b863d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data for fine-tuning \n",
    "loss = losses.TripletLoss(model = model)\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    loss = loss,\n",
    ")\n",
    "\n",
    "# Set up data for fine-tuning \n",
    "trainer.train()\n",
    "# Save the trained model \n",
    "model.save_pretrained(trained_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
